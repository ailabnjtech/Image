# -*- coding: utf-8 -*-
"""VGG19HCNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/AdicherlaVenkataSai/H-CNNforfashionImageclassification/blob/master/VGG19HCNN.ipynb
"""

import keras
import numpy as np
import pickle
import os
from keras.models import Model
from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Input
from keras.initializers import he_normal
from keras import optimizers
from keras.callbacks import LearningRateScheduler, TensorBoard
from keras.layers.normalization import BatchNormalization
from keras.utils.data_utils import get_file
from keras.utils import to_categorical
from keras import backend as K

def scheduler(epoch):
  learning_rate_init = 0.001
  if epoch > 42:
    learning_rate_init = 0.0002
  if epoch > 52:
    learning_rate_init = 0.00005
  return learning_rate_init

def unpickle(filename):
  file = os.path.join(data_dir, filename)
  with open(file, 'rb') as fo:
    dict = pickle.load(fo, encoding='bytes')
  return dict

class LossWeightsModifier(keras.callbacks.Callback):
  def __init__(self, alpha, beta, gamma):
    self.alpha = alpha
    self.beta = beta
    self.gamma = gamma
    # customize your behavior
  def on_epoch_end(self, epoch, logs={}):
    if epoch == 15:
      K.set_value(self.alpha, 0.1)
      K.set_value(self.beta, 0.8)
      K.set_value(self.gamma, 0.1)
    if epoch == 25:
      K.set_value(self.alpha, 0.1)
      K.set_value(self.beta, 0.2)
      K.set_value(self.gamma, 0.7)
    if epoch == 35:
      K.set_value(self.alpha, 0)
      K.set_value(self.beta, 0)
      K.set_value(self.gamma, 1)

height, width = 28, 28
channel = 1
if K.image_data_format() == 'channels_first':
    input_shape = (channel, height, width)
else:
    input_shape = (height, width, channel)

train_size = 60000
test_size = 10000

coarse1_classes = 2

coarse2_classes = 6

num_classes  = 10

batch_size   = 128
epochs       = 60

log_filepath = './tb_log_vgg19_hierarchy_dynamic/'
weights_store_filepath = './vgg19_weights_hierarchy_dynamic/'
retrain_id = '101'
model_name = 'weights_vgg16_fashionmnist'+retrain_id+'.h5'
model_path = os.path.join(weights_store_filepath, model_name)

WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5'
weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',
                         WEIGHTS_PATH,
                         cache_subdir='models')

(train_images, train_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
class_names_c1 = ['Clothes', 'Goods']
class_names_c2 = ['Tops', 'Bottoms', 'Dresses', 'Outers', 'Accessories', 'Shoes']

c2_to_c1 = {0:0, 1:0, 2:0, 3:0, 4:1, 5:1}
fine_to_c2 = {0:0, 1:1, 2:0, 3:2, 4:3, 5:5, 6:0, 7:5, 8:4, 9:5}

def print_mappings(mapping, source, dest):
    for k,v in mapping.items():
        print(source[k], "->", dest[v])

print_mappings(c2_to_c1, class_names_c2, class_names_c1)
print("-"*10)
print_mappings(fine_to_c2, class_names, class_names_c2)

train_images.shape

train_labels_fine = to_categorical(train_labels)
train_labels_fine.shape

test_labels_fine = to_categorical(test_labels)
test_labels_fine.shape

train_labels_c2_index = [fine_to_c2[i] for i in train_labels]
train_labels_c2 = to_categorical(train_labels_c2_index)
train_labels_c2.shape

test_labels_c2_index = [fine_to_c2[i] for i in test_labels]
test_labels_c2 = to_categorical(test_labels_c2_index)
test_labels_c2.shape

train_labels_c1_index = [c2_to_c1[i] for i in train_labels_c2_index]
train_labels_c1 = to_categorical(train_labels_c1_index)
train_labels_c1.shape

test_labels_c1_index = [c2_to_c1[i] for i in test_labels_c2_index]
test_labels_c1 = to_categorical(test_labels_c1_index)
test_labels_c1.shape

x_train = train_images[..., np.newaxis]
x_test = test_images[..., np.newaxis]

y_train = train_labels_fine
y_test = test_labels_fine

y_c1_train = train_labels_c1
y_c1_test = test_labels_c1

y_c2_train = train_labels_c2
y_c2_test = test_labels_c2

print("x_train shape: ", x_train.shape)
print("x_test shape: ", x_test.shape)

print("y_train shape: ", y_train.shape)
print("y_test shape: ", y_test.shape)
print("y_c1_train shape: ", y_c1_train.shape)
print("y_c1_test shape: ", y_c1_test.shape)
print("y_c2_train shape: ", y_c2_train.shape)
print("y_c2_test shape: ", y_c2_test.shape)

alpha = K.variable(value=0.98, dtype="float32", name="alpha") 
beta = K.variable(value=0.01, dtype="float32", name="beta") 
gamma = K.variable(value=0.01, dtype="float32", name="gamma") 

img_input = Input(shape=input_shape, name='input')
img_input

#block 1 
x = Conv2D(64, (3, 3), activation='relu', padding='same')(img_input)
x = BatchNormalization()(x)
x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
x = BatchNormalization()(x)
x = MaxPooling2D((2, 2), strides=(2, 2))(x)

#block 2 
x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
x = BatchNormalization()(x)
x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
x = BatchNormalization()(x)
x = MaxPooling2D((2, 2), strides=(2, 2))(x)

#coarse 1 
c_1_bch = Flatten(name='c1_flatten')(x)
c_1_bch = Dense(256, activation='relu')(c_1_bch)
c_1_bch = BatchNormalization()(c_1_bch)
c_1_bch = Dropout(0.5)(c_1_bch)
c_1_bch = Dense(256, activation='relu')(c_1_bch)
c_1_bch = BatchNormalization()(c_1_bch)
c_1_bch = Dropout(0.5)(c_1_bch)
c_1_pred = Dense(coarse1_classes, activation='softmax')(c_1_bch)

#block 3 
x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)
x = BatchNormalization()(x)
x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)
x = BatchNormalization()(x)
x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)
x = BatchNormalization()(x)
x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)
x = BatchNormalization()(x)
x = MaxPooling2D((2, 2), strides=(2, 2))(x)

#coarse 2
c_2_bch = Flatten(name='c2_flatten')(x)
c_2_bch = Dense(1024, activation='relu')(c_2_bch)
c_2_bch = BatchNormalization()(c_2_bch)
c_2_bch = Dropout(0.5)(c_2_bch)
c_2_bch = Dense(1024, activation='relu')(c_2_bch)
c_2_bch = BatchNormalization()(c_2_bch)
c_2_bch = Dropout(0.5)(c_2_bch)
c_2_pred = Dense(coarse2_classes, activation='softmax')(c_2_bch)

#block 4 
x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)
x = BatchNormalization()(x)
x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)
x = BatchNormalization()(x)
x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)
x = BatchNormalization()(x)
x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)
x = BatchNormalization()(x)
x = MaxPooling2D((2, 2), strides=(2, 2))(x)


#block 5
x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)
x = BatchNormalization()(x)
x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)
x = BatchNormalization()(x)
x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)
x = BatchNormalization()(x)
x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)
x = BatchNormalization()(x)

#fine 
x = Flatten(name='flatten')(x)
x = Dense(4096, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
x = Dense(4096, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
fine_pred = Dense(num_classes, activation='softmax')(x)


model = Model(img_input, [c_1_pred, c_2_pred, fine_pred], name='vgg19_hierarchy')

model.summary()

sgd = optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy', 
              optimizer=sgd, 
              loss_weights=[alpha, beta, gamma], 
              # optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])
tb_cb = TensorBoard(log_dir=log_filepath, histogram_freq=0)
change_lr = LearningRateScheduler(scheduler)
change_lw = LossWeightsModifier(alpha, beta, gamma)
cbks = [change_lr, tb_cb, change_lw]

history = model.fit(x_train, [y_c1_train, y_c2_train, y_train],
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          callbacks=cbks,
          validation_data=(x_test, [y_c1_test, y_c2_test, y_test]))

'''model.compile(loss=keras.losses.categorical_crossentropy,
              # optimizer=keras.optimizers.Adadelta(),
              optimizer=sgd, 
              metrics=['accuracy'])'''

#model.save(model_path)
score = model.evaluate(x_test, [y_c1_test, y_c2_test, y_test], verbose=0)
print('score is: ', score)

# Commented out IPython magic to ensure Python compatibility.
# plot the loss and accuracy

import matplotlib.pyplot as plt
# %matplotlib inline

loss = history.history['loss']
dense_3_loss = history.history['dense_3_loss']
dense_6_loss = history.history['dense_6_loss']
dense_9_loss = history.history['dense_9_loss']
dense_3_accuracy = history.history['dense_3_accuracy']
dense_6_accuracy = history.history['dense_6_accuracy']
dense_9_accuracy = history.history['dense_9_accuracy']
val_loss = history.history['val_loss']
val_dense_3_loss = history.history['val_dense_3_loss']
val_dense_6_loss = history.history['val_dense_6_loss']
val_dense_9_loss = history.history['val_dense_9_loss']
val_dense_3_accuracy = history.history['val_dense_3_accuracy']
val_dense_6_accuracy = history.history['val_dense_6_accuracy']
val_dense_9_accuracy = history.history['val_dense_9_accuracy']

epochs = range(1, 60)

plt.title('Training and validation accuracy')
plt.plot(epochs, dense_3_accuracy, 'red', label='Training C1 accuracy')
plt.plot(epochs, dense_6_accuracy, 'blue', label='Training C2 accuracy')
plt.plot(epochs, dense_9_accuracy, 'green', label='Training F accuracy')
plt.plot(epochs, val_dense_3_accuracy, 'yellow', label='Validation C1 accuracy')
plt.plot(epochs, val_dense_6_accuracy, 'violet', label='Validation C2 accuracy')
plt.plot(epochs, val_dense_9_accuracy, 'gray', label='Validation F accuracy')
plt.legend()

plt.figure()
plt.title('Training and validation loss')
plt.plot(epochs, dense_3_loss, 'red', label='Training C1 loss')
plt.plot(epochs, dense_6_loss, 'blue', label='Training C2 loss')
plt.plot(epochs, dense_9_loss, 'green', label='Training F loss')
plt.plot(epochs, val_dense_3_loss, 'yellow', label='Validation C1 loss')
plt.plot(epochs, val_dense_6_loss, 'violet', label='Validation C2 loss')
plt.plot(epochs, val_dense_9_loss, 'gray', label='Validation F loss')

plt.legend()

plt.show()